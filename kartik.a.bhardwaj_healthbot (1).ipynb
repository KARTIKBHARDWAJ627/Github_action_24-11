{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "S_ieHW2thCTn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet -U langchain==0.2.16\n",
    "!pip install --quiet -U langchain_openai==0.1.23\n",
    "!pip install --quiet -U langgraph==0.2.19\n",
    "!pip install --quiet -U langchainhub==0.1.21\n",
    "!pip install --quiet -U tavily-python==0.4.0\n",
    "!pip install --quiet -U langchain-community==0.2.16\n",
    "!pip install --quiet -U python-dotenv==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uhqed2TrhmPg",
    "outputId": "4397fbb9-6162-4ef7-db88-435ab3a0ec6f"
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"config.env\")\n",
    "assert os.getenv(\"OPENAI_API_KEY\") is not None, \"Missing OpenAI API key!\"\n",
    "assert os.getenv(\"TAVILY_API_KEY\") is not None, \"Missing Tavily API key!\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "flES0-5Whq08"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.prompts import PromptTemplate\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NFNDQLo3hsUB"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Optional\n",
    "\n",
    "class HbotState(TypedDict, total=False):\n",
    "    topic: Optional[str]\n",
    "    summary: Optional[str]\n",
    "    search_results: Optional[str]\n",
    "    patient_answer: Optional[str]\n",
    "    quiz_question: Optional[str]\n",
    "    patient_answer: Optional[str]\n",
    "    grading_result: Optional[str]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KsJoF2XUhumG"
   },
   "outputs": [],
   "source": [
    "def ask_topic(state: HbotState):\n",
    "    # if topic already exists\n",
    "    topic = state.get(\"topic\")\n",
    "\n",
    "    if not topic:\n",
    "        topic = input(\"Enter a health topic: \").strip()\n",
    "        if not topic:\n",
    "            print(\"No input.\")\n",
    "            return {\"end\": True}\n",
    "\n",
    "    print(f\"Starting with topic: {topic}\")\n",
    "    return {\"topic\": topic}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QySfJTtahx7o"
   },
   "outputs": [],
   "source": [
    "def tavily_search(state: HbotState):\n",
    "    from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "    tavily_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "    print(f\"Searching regarding: {state['topic']}...\\n\")\n",
    "    search = tavily_tool.invoke({\"query\": state['topic']})\n",
    "    search_results = \"\\n\".join([doc[\"content\"] for doc in search])\n",
    "    return {\"search_results\": search_results}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5AmVwa60h1L8"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7 , base_url=\"https://openai.vocareum.com/v1\")\n",
    "def result_summary(state: HbotState):\n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "    Explain following medical condition,\n",
    "    using,patient-friendly language and key points take care during that condition.the key points should be in below format:\n",
    "    <<**IMPORTANT**>>\n",
    "    => \n",
    "    =>\n",
    "    =>\n",
    "    Information:\n",
    "    {search_results}\n",
    "    \"\"\")\n",
    "\n",
    "    response = llm.invoke(prompt.format(search_results=state[\"search_results\"]))\n",
    "    summary = response.content\n",
    "    print(\"\\n Here is the info:\\n\")\n",
    "    print(summary)\n",
    "    return {\"summary\": summary}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NX63b0jxh5XZ"
   },
   "outputs": [],
   "source": [
    "def wait_for_quiz(state: HbotState):\n",
    "    input(\"\\n Lets begin a quick QUIZZ...\")\n",
    "    return {\"summary\": state[\"summary\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "swthc2hth7XS"
   },
   "outputs": [],
   "source": [
    "def ask_quiz(state: HbotState):\n",
    "\n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "    Based ONLY on the summary, create ONE multiple-choice question \n",
    "    with four options.Do NOT include the correct answer in the output.\n",
    "    Summary:\n",
    "    {summary}\n",
    "    \"\"\")\n",
    "\n",
    "    quiz = llm.invoke(prompt.format(summary=state[\"summary\"]))\n",
    "    quiz_question = quiz.content\n",
    "    print(\"\\n Quiz Question:\\n\")\n",
    "    print(quiz_question)\n",
    "    return {\"quiz_question\": quiz_question}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6vDFszK0h9NP"
   },
   "outputs": [],
   "source": [
    "def get_answer(state: HbotState):\n",
    "    answer = input(\"\\n Enter your answer: \").strip().upper()\n",
    "    return {\"patient_answer\": answer}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "32O6oAvjh-un"
   },
   "outputs": [],
   "source": [
    "def Quiz_rank(state: HbotState):\n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "    Grade the patient's answer to the question below.\n",
    "    Quiz Question:\n",
    "    {quiz_question}\n",
    "    Patient's Answer: {patient_answer}\n",
    "    Use ONLY the summary below. Provide:\n",
    "    - Letter grade (A–c)\n",
    "    - Short, explanation what he should do while he is going through the condition.\n",
    "    Summary:\n",
    "    {summary}\n",
    "    \"\"\")\n",
    "\n",
    "    result = llm.invoke(prompt.format(\n",
    "        quiz_question=state[\"quiz_question\"],\n",
    "        patient_answer=state[\"patient_answer\"],\n",
    "        summary=state[\"summary\"]\n",
    "    ))\n",
    "\n",
    "    grading_result = result.content\n",
    "    print(\"\\n Here's your result:\\n\")\n",
    "    print(grading_result)\n",
    "    return {\"grading_result\": grading_result}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Gh7B_q_hiAnL"
   },
   "outputs": [],
   "source": [
    "def ask_to_continue(state: HbotState):\n",
    "    choice = input(\"\\nWould you like togo further? (yes/no): \").strip().lower()\n",
    "\n",
    "    if choice in [\"yes\", \"y\"]:\n",
    "        new_topic = input(\" Enter a new health topic you'd like to learn about: \").strip()\n",
    "        if not new_topic:\n",
    "            print(\" No topic entered.\")\n",
    "            return {\"next\": END}\n",
    "        print(\"\\n starting a new topic.\\n\")\n",
    "        return {\"topic\": new_topic, \"next\": \"restart\"}\n",
    "    else:\n",
    "        print(\"\\n Thank you!!\")\n",
    "        # return {\"next\": END}\n",
    "        return {\"topic\": None, \"next\": END}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9pW_ZeDfiD7K"
   },
   "outputs": [],
   "source": [
    "graph = StateGraph(HbotState)\n",
    "graph.add_node(\"ask_topic\", ask_topic)\n",
    "graph.add_node(\"tavily_search\", tavily_search)\n",
    "graph.add_node(\"result_summary\", result_summary)\n",
    "graph.add_node(\"wait_for_quiz\", wait_for_quiz)\n",
    "graph.add_node(\"ask_quiz\", ask_quiz)\n",
    "graph.add_node(\"get_answer\", get_answer)\n",
    "graph.add_node(\"Quiz_rank\", Quiz_rank)\n",
    "graph.add_node(\"ask_to_continue\", ask_to_continue)\n",
    "\n",
    "# order\n",
    "\n",
    "graph.set_entry_point(\"ask_topic\")\n",
    "graph.add_edge(\"ask_topic\", \"tavily_search\")\n",
    "graph.add_edge(\"tavily_search\", \"result_summary\")\n",
    "graph.add_edge(\"result_summary\", \"wait_for_quiz\")\n",
    "graph.add_edge(\"wait_for_quiz\", \"ask_quiz\")\n",
    "graph.add_edge(\"ask_quiz\", \"get_answer\")\n",
    "graph.add_edge(\"get_answer\", \"Quiz_rank\")\n",
    "graph.add_edge(\"Quiz_rank\", \"ask_to_continue\")\n",
    "\n",
    "# Restart or end\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"ask_to_continue\",\n",
    "    lambda x: x[\"next\"],\n",
    "    {\"restart\": \"ask_topic\", END: END}\n",
    ")\n",
    "app = graph.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imq20n04uXgQ",
    "outputId": "56e3d8de-fe70-4f8d-bc70-202806c11dc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a health topic you'd like to learn about: cough\n",
      "Starting with topic: cough\n",
      "Searching regarding: cough...\n",
      "\n",
      "\n",
      " Here is the info:\n",
      "\n",
      "### Understanding Coughing: A Patient-Friendly Explanation\n",
      "\n",
      "A cough is your body's way of protecting itself. When something irritates your throat or airways—like dust, germs, or mucus—your body responds by coughing. This helps clear out those irritants, keeping your airways clean and healthy. While occasional coughing is normal and can help you clear your throat, a persistent cough may signal a more serious issue that needs attention. \n",
      "\n",
      "---\n",
      "\n",
      "### <<**IMPORTANT**>>\n",
      "=> **What Causes a Cough?**\n",
      "   - Coughs can be triggered by many things, including allergies, infections (like colds and flu), chronic lung conditions (like asthma), and even acid reflux.\n",
      "   - Sometimes, irritants like smoke, dust, or strong odors can also cause coughing.\n",
      "\n",
      "=> **When to Seek Medical Help:**\n",
      "   - If your cough lasts more than three weeks (acute cough) or longer than eight weeks (chronic cough), it's important to see a doctor.\n",
      "   - Pay attention if you have other symptoms like shortness of breath, coughing up blood, or producing discolored mucus, as these could indicate a more serious condition.\n",
      "\n",
      "=> **How to Manage a Cough:**\n",
      "   - Over-the-counter medications can help relieve symptoms.\n",
      "   - Drinking honey in warm water may soothe your throat and reduce coughing.\n",
      "   - Stay hydrated to keep mucus thin and easier to expel.\n",
      "\n",
      "---\n",
      "\n",
      "### Additional Information:\n",
      "- Coughing is a natural reflex that helps clear your airways. It can be a sign that your body is trying to get rid of something harmful.\n",
      "- An occasional cough is normal; it's your body’s way of clearing out irritants. However, if you notice a persistent cough with concerning symptoms, don’t hesitate to consult with a healthcare professional.\n",
      "- Common causes of acute cough include colds, bronchitis, and respiratory infections, while chronic coughs could be linked to conditions like asthma or chronic bronchitis.\n",
      "\n",
      "Remember, taking care of your cough early on can prevent more serious issues later. If you're ever in doubt, reaching out to a healthcare provider is the best step to ensure your health and wellbeing.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_topic = input(\"Enter a health topic you'd like to learn about: \")\n",
    "result = app.invoke({\"topic\": user_topic})\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
